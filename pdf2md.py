import logging
import time
import base64
import json
import yaml
import hashlib
from pathlib import Path
from io import BytesIO
import hashlib
from pdf2image import convert_from_path

import pandas as pd
from PIL import Image
from openai import OpenAI

from docling_core.types.doc import PictureItem, TableItem
from docling.datamodel.pipeline_options import PdfPipelineOptions, RapidOcrOptions
from docling.document_converter import DocumentConverter, PdfFormatOption

from prompt.VLM_prompt import VLM_PROMPT
from prompt.text_type_prompt import TEXT_TYPE_PROMPT
from prompt.table_repair_prompt import TABLE_REPAIR_PROMPT


# åŠ è½½é…ç½®æ–‡ä»¶
with open('config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

# === é…ç½® === (ä»é…ç½®æ–‡ä»¶è¯»å–)
ENABLE_OCR = config['OCR']['enabled']
DASHSCOPE_API_KEY = config['VLM']['api_key']
VLM_API_URL = config['VLM']['base_url']
VLM_MODEL = config['VLM']['model']

TEXT_API_KEY = config['OPENAI']['api_key']
TEXT_API_URL = config['OPENAI']['base_url']
TEXT_MODEL = config['OPENAI']['model']

input_pdf_path = Path("D:/Personal_Project/SmolDocling/pdfs/APD_Series_203250D.pdf")

# æ ¹æ® PDF æ–‡ä»¶è·¯å¾„ç”Ÿæˆå“ˆå¸Œå€¼
def generate_hash_from_file(file_path: Path) -> str:
    md5_hash = hashlib.md5()
    with file_path.open("rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            md5_hash.update(chunk)
    return md5_hash.hexdigest()

# è·å–å“ˆå¸Œå€¼ä½œä¸ºå­ç›®å½•å
pdf_hash = generate_hash_from_file(input_pdf_path)
output_dir = Path.cwd() / "output" / pdf_hash
output_dir.mkdir(parents=True, exist_ok=True)
doc_filename = input_pdf_path.stem

# === è·å–PDFæ¯é¡µå¹¶ä¿å­˜ä¸ºå›¾ç‰‡ ===
def convert_pdf_to_images(pdf_path: Path, output_dir: Path):
    # ä»é…ç½®ä¸­è·å– Poppler è·¯å¾„
    poppler_path = Path(config['POPPLER']['path'])

    # åˆ›å»º page å­ç›®å½•
    page_dir = output_dir / "page"
    page_dir.mkdir(parents=True, exist_ok=True)

    # ä½¿ç”¨ pdf2image å°†æ¯ä¸€é¡µè½¬æ¢ä¸ºå›¾ç‰‡
    pages = convert_from_path(
        pdf_path,
        dpi=300,  # 300 DPI
        poppler_path=str(poppler_path)
    )

    for page_num, page in enumerate(pages, start=1):
        page_image_filename = page_dir / f"page-{page_num}.png"
        page.save(page_image_filename, 'PNG')
        log.info(f"ä¿å­˜ PDF ç¬¬ {page_num} é¡µï¼š{page_image_filename.resolve()}")

# === å›¾åƒ + Prompt â†’ Markdown è¡¨æ ¼ï¼ˆQwenï¼‰===
def ask_table_from_image(pil_image: Image.Image, prompt: str = TABLE_REPAIR_PROMPT) -> str:
    try:
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

        client = OpenAI(api_key=DASHSCOPE_API_KEY, base_url=VLM_API_URL)
        content = [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"}}
        ]
        completion = client.chat.completions.create(
            model=VLM_MODEL,
            messages=[{"role": "user", "content": content}]
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        log.warning(f"âŒ è¡¨æ ¼å›¾åƒä¿®å¤å¤±è´¥: {e}")
        return "[è¡¨æ ¼ä¿®å¤å¤±è´¥]"


# === å›¾ç‰‡æè¿° ===
def ask_image_vlm_base64(pil_image: Image.Image, prompt: str = VLM_PROMPT) -> str:
    try:
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        client = OpenAI(api_key=DASHSCOPE_API_KEY, base_url=VLM_API_URL)
        content = [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"}}
        ]
        completion = client.chat.completions.create(
            model="qwen-vl-plus",
            messages=[{"role": "user", "content": content}]
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        log.warning(f"å›¾åƒAPIå¤±è´¥: {e}")
        return "[å›¾åƒæè¿°å¤±è´¥]"


# === åˆ¤æ–­æ–‡æœ¬ç±»å‹ï¼ˆæ ‡é¢˜ or æ­£æ–‡ï¼‰===
def ask_if_heading(text: str) -> str:
    try:
        client = OpenAI(api_key=TEXT_API_KEY, base_url=TEXT_API_URL)
        prompt = f"{TEXT_TYPE_PROMPT}\n{text}"
        response = client.chat.completions.create(
            model=TEXT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        answer = response.choices[0].message.content.strip().lower()
        return "heading" if "heading" in answer else "paragraph"
    except Exception as e:
        log.warning(f"åˆ¤æ–­æ ‡é¢˜/æ­£æ–‡å¤±è´¥: {e}")
        return "paragraph"


# === è¡¨æ ¼å›¾åƒåˆ‡å—å·¥å…·ï¼ˆæŒ‰å›ºå®šè¡Œé«˜è£åˆ‡ï¼‰ ===
def split_table_image_rows(pil_img: Image.Image, row_height: int = 400) -> list:
    width, height = pil_img.size
    slices = []
    for top in range(0, height, row_height):
        bottom = min(top + row_height, height)
        crop = pil_img.crop((0, top, width, bottom))
        slices.append(crop)
    return slices

# === è·å–å…ƒç´ çš„è¾¹ç•Œæ¡† ===
def get_bbox(element):
    if hasattr(element, 'prov') and element.prov:
        bbox = element.prov[0].bbox
        return {
            "left": bbox.l,
            "top": bbox.t,
            "right": bbox.r,
            "bottom": bbox.b,
            "coord_origin": bbox.coord_origin
        }
    return None

# === ä¸»æµç¨‹ ===
def convert_pdf_to_markdown_with_images():
    start_time = time.time()
    pipeline_options = PdfPipelineOptions()
    pipeline_options.images_scale = 2.0
    pipeline_options.generate_picture_images = True
    pipeline_options.generate_table_images = True

    if ENABLE_OCR:
        pipeline_options.do_ocr = True
        pipeline_options.ocr_options = RapidOcrOptions(force_full_page_ocr=True)

    doc_converter = DocumentConverter(
        format_options={"pdf": PdfFormatOption(pipeline_options=pipeline_options)}
    )
    conv_res = doc_converter.convert(input_pdf_path)
    document = conv_res.document

    markdown_lines = []
    json_data = []
    table_counter = 0
    picture_counter = 0

    # è·å–å¹¶ä¿å­˜ PDF æ¯ä¸€é¡µä¸ºå›¾ç‰‡
    convert_pdf_to_images(input_pdf_path, output_dir)

    for element, level in document.iterate_items():
        # è·å–å…ƒç´ çš„è¾¹ç•Œæ¡†
        bbox = get_bbox(element)

        if isinstance(element, TableItem):
            table_counter += 1
            # ä½¿ç”¨å“ˆå¸Œå€¼ç”Ÿæˆå›¾ç‰‡/è¡¨æ ¼æ–‡ä»¶å
            table_image_filename = output_dir / f"{pdf_hash}-table-{table_counter}.png"
            pil_img = element.get_image(document)
            pil_img.save(table_image_filename, "PNG")
            table_df: pd.DataFrame = element.export_to_dataframe()

            if not table_df.columns.is_unique or table_df.shape[1] < 2:
                log.warning(f"âš ï¸ è¡¨æ ¼ {table_counter} ç»“æ„å¼‚å¸¸ï¼Œä½¿ç”¨ Qwen å¤šè½®å›¾åƒæ¨ç†ä¿®å¤")

                # è‡ªåŠ¨å›¾åƒåˆ‡å—
                sub_images = split_table_image_rows(pil_img)
                all_chunks = []

                for idx, chunk_img in enumerate(sub_images):
                    chunk_md = ask_table_from_image(chunk_img)
                    all_chunks.append(chunk_md.strip())

                # æ‹¼æ¥å¤šæ®µ Markdown è¡¨æ ¼ï¼ˆä¿ç•™é¦–æ®µè¡¨å¤´ï¼‰
                full_md_lines = []
                for i, chunk in enumerate(all_chunks):
                    lines = chunk.splitlines()
                    if i == 0:
                        full_md_lines.extend(lines)  # ä¿ç•™è¡¨å¤´ + åˆ†å‰²çº¿
                    else:
                        full_md_lines.extend(lines[2:])  # ä»…æ·»åŠ æ•°æ®è¡Œ

                markdown_lines.append(f"\n<!-- è¡¨æ ¼ {table_counter} ä½¿ç”¨ Qwen ä¿®å¤ï¼Œå·²åˆ†å—æ‹¼æ¥ -->\n")
                markdown_lines.append("\n".join(full_md_lines))
                markdown_lines.append("")
                json_data.append({
                    "type": "table",
                    "level": level,
                    "image": table_image_filename.name,
                    "source": "reconstructed_by_qwen_chunked",
                    "markdown": "\n".join(full_md_lines),
                    "page_number": element.prov[0].page_no,  # Add page number to JSON
                    "bbox": bbox  # æ·»åŠ è¾¹ç•Œæ¡†åˆ° JSON
                })
                continue  # è·³è¿‡åŸå§‹å¤„ç†

            # âœ… è¡¨æ ¼ç»“æ„æ­£å¸¸
            markdown_lines.append(table_df.to_markdown(index=False))
            markdown_lines.append("")
            json_data.append({
                "type": "table",
                "level": level,
                "image": table_image_filename.name,
                "data": table_df.to_dict(orient="records"),
                "page_number": element.prov[0].page_no,  # Add page number to JSON
                "bbox": bbox  # æ·»åŠ è¾¹ç•Œæ¡†åˆ° JSON
            })

        elif isinstance(element, PictureItem):
            picture_counter += 1
            # ä½¿ç”¨å“ˆå¸Œå€¼ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶å
            picture_image_filename = output_dir / f"{pdf_hash}-picture-{picture_counter}.png"
            pil_img = element.get_image(document)
            pil_img.save(picture_image_filename, "PNG")
            caption = ask_image_vlm_base64(pil_img)

            # ç”Ÿæˆå›¾ç‰‡é“¾æ¥ + æè¿°ä¸ºå›¾ç‰‡æ ‡é¢˜
            markdown_lines.append(f"\n![{caption}](./{picture_image_filename.name})\n")
            json_data.append({
                "type": "picture",
                "level": level,
                "image": picture_image_filename.name,
                "caption": caption,
                "page_number": element.prov[0].page_no,  # Add page number to JSON
                "bbox": bbox  # æ·»åŠ è¾¹ç•Œæ¡†åˆ° JSON
            })

        else:
            if hasattr(element, "text") and element.text:
                text = element.text.strip()
                if text:
                    label = ask_if_heading(text)
                    markdown_lines.append(f"# {text}" if label == "heading" else text)
                    markdown_lines.append("")
                    json_data.append({
                        "type": "text",
                        "level": level,
                        "text": text,
                        "label": label,
                        "page_number": element.prov[0].page_no,  # Add page number to JSON
                        "bbox": bbox  # æ·»åŠ è¾¹ç•Œæ¡†åˆ° JSON
                    })

    # ä¿å­˜ç»“æœ
    markdown_file = output_dir / f"{pdf_hash}.md"
    with markdown_file.open("w", encoding="utf-8") as f:
        f.write("\n".join(markdown_lines))

    json_file = output_dir / f"{pdf_hash}.json"
    with json_file.open("w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

    log.info(f"âœ… å®Œæˆ PDF è§£æï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’")
    log.info(f"ğŸ“„ Markdown æ–‡ä»¶ï¼š{markdown_file.resolve()}")
    log.info(f"ğŸ“¦ JSON æ–‡ä»¶ï¼š{json_file.resolve()}")

if __name__ == "__main__":
    convert_pdf_to_markdown_with_images()
